<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Blog :: Audio Spectrum Analysis</title>
    <link rel="stylesheet" href="style.css">
    <link href="https://fonts.googleapis.com/css2?family=Press+Start+2P&display=swap" rel="stylesheet">
    <style>
        /* Add specific styles for the video containers to match the aesthetic */
        .retro-media-box {
            background: #000;
            border: 4px solid #444;
            box-shadow: 5px 5px 0px #222;
            padding: 10px;
            margin: 2rem 0;
            text-align: center;
        }

        .retro-media-box video, .retro-media-box img {
            width: 100%;
            height: auto;
            display: block;
            /* slight sepia/contrast filter for retro monitor feel */
            filter: contrast(1.1) brightness(0.9); 
        }

        .retro-caption {
            font-size: 0.7rem;
            color: #888;
            margin-top: 0.5rem;
            font-style: italic;
        }
    </style>
</head>
<body>
    <div id="custom-cursor"></div>
    <div id="particle-canvas"></div>
    
    <audio id="audio-hover" src="hover.wav" preload="auto"></audio>
    <audio id="audio-click" src="click.wav" preload="auto"></audio>
    <audio id="audio-start" src="start.wav" preload="auto"></audio>
    <canvas id="gl-canvas"></canvas>

    <div class="container is-hidden">
    
    <nav style="margin-bottom: 3rem; margin-top: 1rem;">
        <a href="index.html" class="social-btn back-btn">
            <span>&lt; Back to Home</span>
        </a>
    </nav>

    <header class="header" style="margin-bottom: 3rem;">
        <h1 class="name-title" data-text="Audio Spectrum Analysis">Audio Spectrum Analysis</h1>
        <p class="subtitle">~ Jan 31, 2026 ~</p>
    </header>

    <main>
        <article class="section">
            <div class="section-title-wrapper">
                <h2 class="section-title" data-text="> Understanding the DFT"></h2>
            </div>
            
            <div class="nes-container with-title is-dark blog-content">
                <p class="title">DftCore.cpp</p>
                
                <p>To analyze audio signals programmatically, we must bridge the gap between the time domain and the frequency domain. The Discrete Fourier Transform (DFT) is the mathematical key to this portal.</p>
                
                <br>
                
                <div style="text-align: center; margin: 2rem 0; padding: 1rem; border: 2px dashed #444;">
                    <img src="dfteq.png" alt="DFT Equation" style="max-width: 100%; height: auto; image-rendering: pixelated;">
                </div>

                <p>e^-j(2&pi;kn/N) can be thought of as the complex "weight" or amplitude of the kth frequency. In this case, the kth frequency is one whose samples are spread over k rotations over the complex unit circle.</p>
                
                <br>
                <h3>Why use e^i&theta; over just cosine waves (or sine waves)?</h3>
                <p>You might ask: Why introduce complex numbers? Why not just correlate with standard cosine waves? This is one thing I initially was confused about.</p>
                
                <p>The problem with a simple cosine wave is that it is <strong>phase blind</strong>. Let's say your audio signal is a pure sine wave of frequency 3 Hz, correlating it with a Cosine wave of 3 hz results in zero, because they are orthogonal (90 degrees out of phase). The math would wrongly tell you that the frequency doesn't exist.</p>

                <p>Complex numbers solve this by using Euler's formula to project the signal against <em>both</em> a cosine (Real axis) and a sine (Imaginary axis) simultaneously. This gives us a 2D "coordinate" for every frequency bin, allowing us to recover the exact alignment:</p>
                
                <ul style="list-style-type: square; padding-left: 20px; color: #ccc;">
                    <li style="margin-bottom: 10px;"><strong>Magnitude:</strong> sqrt(Real^2 + Imag^2) (Total energy)</li>
                    <li><strong>Phase:</strong> atan(Imag, Real) (The starting angle)</li>
                </ul>

                <p>With <span style="color: #ffcc00;">atan</span>, we can precisely calculate the phase shift required to reconstruct the original signal.</p>

                <br>

                <h3>Programming the naive DFT - Starting with a Single Bin</h3>
                <p>First, we define a function to calculate the energy for just <strong>one specific frequency</strong> (k). This projects the signal onto a specific sine/cosine wave.</p>

                <div class="code-block">
                    <pre>
struct Complex { float Real; float Imag; };

// Calculate DFT bin for a specific frequency index K
Complex DftBin(const std::vector<float>& Signal, int K) {
    int N = Signal.size();
    Complex Xk = {0.0f, 0.0f};
    
    for (int n = 0; n < N; n++) {
        // Euler's Formula: e^-ix = cos(x) - i*sin(x)
        float theta = -2.0f * PI * K * n / N;
        
        Xk.Real += Signal[n] * std::cos(theta);
        Xk.Imag += Signal[n] * std::sin(theta);
    }
    return Xk;
}
</pre>
</div>
<br>

                <h3>Programming the Full Spectrum DFT</h3>
                <p>To build the complete frequency spectrum, we simply iterate through every possible integer frequency from 0 to N-1, collecting the results into a vector.</p>

                <div class="code-block">
                    <pre>
// The naive O(N^2) DFT implementation
std::vector<Complex> FullDFT(const std::vector<float>& Signal) {
    int N = Signal.size();
    std::vector<Complex> Spectrum;
    
    // Iterate through every frequency bin K
    for (int k = 0; k < N; k++) {
        Spectrum.push_back(DftBin(Signal, k));
    }
    return Spectrum;
}
</pre>
</div>
<br>
                <h3>Why is k integral exactly?</h3>
                <p>You might wonder why <span style="color: #ffcc00;">k</span> is always an integer (0, 1, 2...) rather than a decimal like 2.5.</p>
                
                <p>The DFT assumes the signal of length N is periodic. For the math to work orthogonally, we are testing how many <strong>complete cycles</strong> fit exactly into our window of N samples.</p>
                
                <p>If <span style="color: #ffcc00;">k=1</span>, the wave fits once. If <span style="color: #ffcc00;">k=2</span>, it fits twice. These integer frequencies form a basis - a coordinate system for the signal space. If we used non-integers, our "coordinates" would overlap, breaking the clean decomposition of the signal.</p>

                <br>
                <h3>Visualizing the Wrap using a "Winding Machine"</h3>
                <p>The core mechanic of the DFT is "wrapping" the signal around the origin. When the wrap rate matches a frequency in the signal, the points line up.</p>

                <div class="retro-media-box">
                    <video src="DFTWrapAroundScene.mp4" autoplay loop muted playsinline onloadeddata="this.playbackRate=1.1"></video>
                    <div class="retro-caption">Fig 1. Signal wrapping vs Center of Mass</div>
                </div>

                <p>Notice how the "Center of Mass" (the red dot) stays near the center (0,0) for most frequencies. However, when the winding frequency matches the signal's frequency, the graph aligns to the right, pulling the center of mass away from the origin. That distance is the magnitude of the frequency.</p>

                <br>
                <h3>Ok, now what if my frequency isn't integral?</h3>
                <p>Real-world audio doesn't care about our integer bins. A guitar string might vibrate at a frequency that lands at <span style="color: #ffcc00;">k = 5.4</span>.</p>

                <div class="retro-media-box">
                    <video src="SpectralLeakageScene.mp4" autoplay loop muted playsinline onloadeddata="this.playbackRate=1.1"></video>
                    <div class="retro-caption">Fig 2. Discontinuity causing Energy Leakage</div>
                </div>

                <p>When the frequency doesn't complete a full cycle within the window N, the endpoints don't match up. This creates a sharp discontinuity if we were to loop the signal.</p>
                
                <p>The DFT interprets this sharp jump as a burst of energy across many frequencies. Consequently, the energy "leaks" from the main frequency bin into its neighbors. This is called <strong>Spectral Leakage</strong>.</p>
                
                <br>
                <h3>The Short Time Fourier Transform</h3>
                <p>The standard DFT has a fatal flaw: it is <strong>timeless</strong>.</p>
                
                <p>If you take the DFT of an entire song, the math will tell you exactly which notes were played, but it cannot tell you <em>when</em> they were played. A C-major chord played at the beginning looks mathematically identical to one played at the end.</p>
                
                <p>To solve this, we don't process the whole signal at once. Instead, we chop the signal into small, overlapping blocks (or "windows") and run the DFT on each block individually. This technique, the <strong>STFT</strong>, allows us to see how frequencies evolve over time.</p>

                <div class="retro-media-box">
                    <video src="STFT.mp4" autoplay loop muted playsinline onloadeddata="this.playbackRate=1.1"></video>
                    <div class="retro-caption">Fig 3. Sliding window analysis (STFT)</div>
                </div>
                
                <br>

                <h3>The Periodicity Assumption</h3>
                <p>When we slice audio into blocks for the STFT, the math inherently assumes that each small block repeats infinitely. However, because our cuts are arbitrary, the end of the block rarely lines up with the start.</p>
                
                <div class="retro-media-box">
                    <video src="periodicityassumption.mp4" autoplay loop muted playsinline onloadeddata="this.playbackRate=1.1"></video>
                    <div class="retro-caption">Fig 4. The "Cliff" created by raw slicing</div>
                </div>

                <p>This mismatch creates a sharp discontinuity - a "cliff" - every time the loop repeats. To the DFT, this cliff looks like a burst of high-frequency noise, muddying our analysis.</p>

                <br>
                <h3>The Hann Filter</h3>
                <p>To fix the cliff, we cheat. We multiply the block by a "Window Function" like the <strong>Hann Filter</strong> before processing it. This shapes the audio into a smooth bell curve, tapering the jagged edges down to zero. We can then undo this transformation while taking the IDFT (inverse transform).</p>

                <div class="retro-media-box">
                    <video src="han.mp4" autoplay loop muted playsinline onloadeddata="this.playbackRate=1.1"></video>
                    <div class="retro-caption">Fig 5. Smoothing the edges with a Window</div>
                </div>

                <p>Now, when the blocks repeat, the start and end points meet perfectly at silence. By making the signal periodic and continuous, we get a clean, accurate frequency reading.</p>
                
                <br>
                <h3>Time vs Frequency Res Tradeoff</h3>
                <p>Nature *demands* a price. We encounter a limit similar to the Heisenberg Uncertainty Principle.</p>
                
                <ul style="list-style-type: square; padding-left: 20px; color: #ccc;">
                    <li style="margin-bottom: 10px;">To get precise <strong>Time</strong> information, we need very short windows.</li>
                    <li>To get precise <strong>Frequency</strong> information, we need very long windows (larger N).</li>
                </ul>
                
                <p>If we shrink our window to pinpoint the exact millisecond a drum hit, our frequency bins become wide and coarse (poor resolution). If we widen the window to distinguish between 440Hz and 441Hz, we smear the event out over time.</p>

                <div class="retro-media-box">
                    <video src="res.mp4" autoplay loop muted playsinline onloadeddata="this.playbackRate=1.1"></video>
                    <div class="retro-caption">Fig 6. The Uncertainty Principle visualised</div>
                </div>

                <blockquote>
                    "We are forever trapped between knowing when it happened, and knowing exactly what it was."
                </blockquote>

                <br>

                <h3>Generating audio spectrum</h3>
                <p>Now that we can generate frequency data for set time intervals via the STFT, we can plot them sequentially. By mapping Time to the X-axis and Frequency to the Y-axis, we obtain a heat map of the sound.</p>

                <p>Adjusting the visual scales and mapping amplitude to color intensity allows us to "Look" at our audio from a new perspective. We can visually distinguish the transient snap of a snare drum from the steady harmonic layers of a synthesizer.</p>

                <div class="retro-media-box">
                    <img src="spectrum.png" alt="Audio Spectrum" style="image-rendering: pixelated;">
                    <div class="retro-caption">Fig 7. Visualizing the Frequency Domain</div>
                </div>

                <br>

                <h3>Drawing Audio!</h3>
                <p>The transformation is bidirectional. We can add a brush tool and suddenly we're able to draw audio directly onto the spectrogram.</p>

                <p>By painting onto the frequency canvas and running the Inverse DFT (IDFT), we convert the image back into sound waves. It is surprisingly effective; drawing a shape that "looks" like a chirp generally sounds like a chirp. We can essentially sculpt sound like clay.</p>

                <div class="retro-media-box">
                    <img src="drawingaudio.png" alt="Drawing Audio Tool" style="image-rendering: pixelated;">
                    <div class="retro-caption">Fig 8. Inverse FFT Painting</div>
                </div>

                <br>

                <h3>Conclusion</h3>
                <p>It is genuinely amazing that we can effectively "paint" sound. By simply changing the "perspective" with which we look at audio, we can do so much more.</p>

                <p>You can check out the full source code for this project here: <a href="https://github.com/swr06/AudioAnalyzer" target="_blank" style="color: #ffcc00;">AudioAnalyzer</a>.</p>
				<p>And a video that demonstrates it : <a href="https://www.youtube.com/watch?v=XEH2yinbaYA" target="_blank" style="color: #ffcc00;">Youtube</a>.</p>

            </div>
        </article>
    </main>

    <footer class="footer">
         <div class="section-title-wrapper"><h2 class="section-title" data-text="> Connect"></h2></div>
         <div class="social-links">
            <a href="https://github.com/swr06/" target="_blank" class="social-btn"><img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/github/github-original.svg" alt="GitHub"><span>GitHub</span></a>
            <a href="https://x.com/SamuelRasquinha" target="_blank" class="social-btn"><img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/twitter/twitter-original.svg" alt="Twitter/X"><span>Twitter</span></a>
        </div>
    </footer>
    </div>

<script src="webgl-background.js"></script>
<script src="app.js"></script>
<script>
(function() {
  const isMobile = /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent);
  if (isMobile) return;

  const canvas = document.getElementById('particle-canvas');
  if (!canvas) return;

  const particles = [];
  const gravity = 0.2; 

  document.addEventListener('mousemove', function(e) {
    if (Math.random() > 0.4) createParticle(e.clientX, e.clientY, 'trail');
  });

  document.addEventListener('click', function(e) {
    for (let i = 0; i < 20; i++) createParticle(e.clientX, e.clientY, 'burst');
  });

  function createParticle(x, y, type) {
    const particle = {
      element: document.createElement('div'),
      x: x,
      y: y,
      vx: 0,
      vy: 0,
      size: 0,
      life: 0,
      initialLife: 0,
      bounces: 2
    };

    if (type === 'trail') {
      const angle = Math.random() * Math.PI * 2;
      const speed = Math.random() * 0.5;
      particle.vx = Math.cos(angle) * speed;
      particle.vy = Math.sin(angle) * speed;
      particle.size = Math.random() * 3 + 2;
      particle.life = Math.random() * 20 + 45;
    } else { 
      const angle = Math.random() * Math.PI * 2;
      const speed = Math.random() * 2.5 + 1; 
      particle.vx = Math.cos(angle) * speed;
      particle.vy = Math.sin(angle) * speed - 2;
      particle.size = Math.random() * 5 + 3;
      particle.life = Math.random() * 50 + 110;
    }

    particle.initialLife = particle.life;
    particle.element.classList.add('particle');
    particle.element.style.width = `${particle.size}px`;
    particle.element.style.height = `${particle.size}px`;
    particle.element.style.background = `hsl(${Math.random() * 50 + 90}, 90%, 60%)`;
    
    canvas.appendChild(particle.element);
    particles.push(particle);
  }

  function update() {
    for (let i = particles.length - 1; i >= 0; i--) {
      const p = particles[i];
      p.vy += gravity;
      p.x += p.vx;
      p.y += p.vy;
      p.life--;

      if (p.y + p.size >= window.innerHeight && p.bounces > 0) {
        p.y = window.innerHeight - p.size;
        p.vy *= -0.5;
        p.vx *= 0.7;
        p.bounces--;
      }

      if (p.life <= 0) {
        p.element.remove();
        particles.splice(i, 1);
        continue;
      }

      p.element.style.transform = `translate3d(${p.x}px, ${p.y}px, 0)`;
      p.element.style.opacity = p.life / p.initialLife;
    }
    requestAnimationFrame(update);
  }
  requestAnimationFrame(update);
})();
</script>
</body>
</html>